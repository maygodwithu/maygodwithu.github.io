<br>
- Ice breaking<br>
(1) Hello! My name is Jack Choi.<br>
(2) I’m so glad to meet you in person.<br>
(3) MonoBERT is always a reference paper for my studies. <br>
(4) When I studied sequence to sequence in deep learning class, I learned it from your theory. <br>
(4) It is an honor for me to see you.<br>
(5) I know you're very busy, but thank you for replying to my mail and taking the time to have a meeting like this.<br>
<br>
-Introduction<br>
(6) I have been working as a programmer in a NAVER search team for 18 years.<br>
(7) I finished my master's course when I was in my twenties, but I really wanted to be a PH.D, so I started a PH.D course at a late age.<br>
(8) I majored in Information Retrial and NLP at Seoul National University, and I will receive my PH.D. in August.<br>
(9) Currently, I am studying neural ranking models and developing a chat-bot using GPT3.<br>
(10) I’m heavily interested in Information retrieval and Natural language processing.<br>
(11) During my stay in the United States, I hope to continue research related to this topic.<br>
(12) After I am receiving my PH.D in August, I hope to stay in the United States from August this year to August next year.<br>
<br>
-Goal of my visiting<br>
(13) There are two main reasons why I want to be a visiting researcher.<br>
(14) First, I want to do research with the leaders in AI field like you. <br>
(15) I've always wondered how they did such great research.<br>
(16) So, I had a desire to meet and discuss them who are in the leading group.<br>
(17) Second, I want to experience college life in the United States. <br>
(18) After returning to Korea, I plan to try to become a professor.<br>
(19) In order to teach students well, I want to understand and learn universities in other countries, about how they teach and learn or something like that.<br>
(20) I dream of becoming a good professor.<br>
<br>
- Research topic<br>
(21) This month, I started the pre-training project of the neural ranking models between the Seoul National University and Naver.<br>
(22) The goal of the project is to devise a pre-training method tailored only for IR.<br>
(23) Usually, NRMs has the architecture that connects directly from pre-training to fine-tuning.<br>
(24) But I think we need, in the middle of the two, another pre-training method only for ranking models.<br>
(25) Because a fine-tuning method is not sufficient for changing pre-trained models totally into new models for ranking tasks.<br> 
(26) There are already several papers on this, and our purpose is to suggest a better way than those researches.<br>
(27) Beside this topic, I am also working on a study to analyze BERT's representaion from an IR perspective.<br>
(28) I don't know yet which one will be a successful research, but both are my interests and topics I'm going to proceed with this year.
<br>
- Cost <br>
(29) If it is confirmed that I will be a visiting scholar, I can negotiate with Naver how I should work for NAVER.<br>
(30) I'm expecting that the company will send me to the United States, but I know that life doesn't just flow in the direction I want.<br>
(31) In the case NAVER doesn't let me go, I'll take a year off from work and go to the United States.<br>
(32) No matter what condition I go with, the research itself is connected to the company, so if the paper comes out, I think it will be written in collaboration with Seoul National University, Naver, and you.<br>
(33) I’m planning to cover the cost for staying US with stock options.<br>
<br>
- Ending <br>
(34) It was nice to meet you today.<br>
(35) Thank you for the meeting with me.<br>
(36) I’m looking forward to your answer.<br>
(37) Thank you.<br>
